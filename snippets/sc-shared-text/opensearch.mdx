Connect OpenSearch to your preprocessing pipeline, and batch process all your documents using `unstructured-ingest` to store structured outputs locally on your filesystem.

First, install the OpenSearch dependencies as shown here.

```bash
pip install "unstructured-ingest[opensearch]"
```

Configure OpenSearch connection parameters:
* `index-name`: Name of the OpenSearch index to pull data from.
* `hosts`: List of the OpenSearch hosts to connect to, e.g. `"http://localhost:9200"`
* `index-name`: Index name to ingest data from>
* `username`: Username to authenticate into the index
* `password`: Password to authenticate into the index
* `use-ssl`: Specify whether to use ssl for the connection.
* `verify-certs`: Specify whether to verify SSL certificates.
* `ssl-show-warn`: Specify whether to show a warning when verify certs is disabled.
* `ca-certs`: Path to CA bundle
* `client-cert`: Path to the file containing the private key and the certificate or cert only if using `client_key`.
* `client-key`: Path to the file containing the private key if using separate cert and key files.

Optionally, specify:
* `fields`: Comma-delimited list of OpenSearch fields to limit the data ingestion to
* `batch-size`:  Number of records to read at a time per process
