Batch process all your records using `unstructured-ingest` to store structured outputs locally on your filesystem and upload those local files to an S3 bucket.

First you’ll need to install the S3 dependencies as shown here.

```bash
pip install "unstructured[s3]"
```

The upstream connector can be any of the ones supported, but for convenience here, showing a sample command using the upstream local connector.

import S3Sh from '/snippets/destination_connectors/s3.sh.mdx';
import S3Py from '/snippets/destination_connectors/s3.py.mdx';

<CodeGroup>

  <S3Sh />

  <S3Py />

</CodeGroup>


For a full list of the options the CLI accepts check `unstructured-ingest <upstream connector> s3 --help`.

NOTE: Keep in mind that you will need to have all the appropriate extras and dependencies for the file types of the documents contained in your data storage platform if you’re running this locally. You can find more information about this in the [installation guide](/open-source/installation/overview).