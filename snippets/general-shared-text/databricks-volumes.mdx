The Databricks Volumes prerequisites:

<iframe
width="560"
height="315"
src="https://www.youtube.com/embed/rNZpwa1-g7M"
title="YouTube video player"
frameborder="0"
allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
allowfullscreen
></iframe>

The preceding video shows how to use Databricks personal access tokens (PATs), which are supported only for [Unstructured Ingest](/ingestion/overview).

To learn how to use Databricks-managed service principals, which are supported by both the [Unstructured Platform](/platform/overview) and Unstructured Ingest, 
see the additional videos later on this page.

- The Databricks workspace URL. Get the workspace URL for 
  [AWS](https://docs.databricks.com/workspace/workspace-details.html#workspace-instance-names-urls-and-ids), 
  [Azure](https://learn.microsoft.com/azure/databricks/workspace/workspace-details#workspace-instance-names-urls-and-ids), 
  or [GCP](https://docs.gcp.databricks.com/workspace/workspace-details.html#workspace-instance-names-urls-and-ids).

  Examples:

  - AWS: `https://<workspace-id>.cloud.databricks.com`
  - Azure: `https://adb-<workspace-id>.<random-number>.azuredatabricks.net`
  - GCP: `https://<workspace-id>.<random-number>.gcp.databricks.com`

- The Databricks authentication details. For more information, see the documentation for 
  [AWS](https://docs.databricks.com/dev-tools/auth/index.html), 
  [Azure](https://learn.microsoft.com/azure/databricks/dev-tools/auth/), 
  or [GCP](https://docs.gcp.databricks.com/dev-tools/auth/index.html).

  The following videos show how to create a Databricks-managed service principal and then grant it access to a Databricks volume:

  <iframe
  width="560"
  height="315"
  src="https://www.youtube.com/embed/wBmqv5DaA1E"
  title="YouTube video player"
  frameborder="0"
  allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
  allowfullscreen
  ></iframe>

  <iframe
  width="560"
  height="315"
  src="https://www.youtube.com/embed/DykQRxgh2aQ"
  title="YouTube video player"
  frameborder="0"
  allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
  allowfullscreen
  ></iframe>

  For the [Unstructured Platform](/platform/overview), only the following Databricks authentication type is supported:
  
  - For OAuth machine-to-machine (M2M) authentication (AWS, Azure, and GCP): The client ID and OAuth secret values for the corresponding service principal.
    Note that for Azure, only Databricks-managed service principals are supported. Microsoft Entra ID-managed service principals are not supported.
  
  For [Unstructured Ingest](/ingestion/overview), the following Databricks authentication types are supported:

  - For Databricks personal access token authentication (AWS, Azure, and GCP): The personal access token's value.
  - For username and password (basic) authentication (AWS only): The user's name and password values.
  - For OAuth machine-to-machine (M2M) authentication (AWS, Azure, and GCP): The client ID and OAuth secret values for the corresponding service principal.
  - For OAuth user-to-machine (U2M) authentication (AWS, Azure, and GCP): No additional values.
  - For Azure managed identities (MSI) authentication (Azure only): The client ID value for the corresponding managed identity.
  - For Microsoft Entra ID service principal authentication (Azure only): The tenant ID, client ID, and client secret values for the corresponding service principal.
  - For Azure CLI authentication (Azure only): No additional values.
  - For Microsoft Entra ID user authentication (Azure only): The Entra ID token for the corresponding Entra ID user.
  - For Google Cloud Platform credentials authentication (GCP only): The local path to the corresponding Google Cloud service account's credentials file.
  - For Google Cloud Platform ID authentication (GCP only): The Google Cloud service account's email address.

- The Databricks catalog name for the volume. Get the catalog name for [AWS](https://docs.databricks.com/catalogs/manage-catalog.html), [Azure](https://learn.microsoft.com/azure/databricks/catalogs/manage-catalog), or [GCP](https://docs.gcp.databricks.com/catalogs/manage-catalog.html).
- The Databricks schema name for the volume. Get the schema name for [AWS](https://docs.databricks.com/schemas/manage-schema.html), [Azure](https://learn.microsoft.com/azure/databricks/schemas/manage-schema), or [GCP](https://docs.gcp.databricks.com/schemas/manage-schema.html).
- The Databricks volume name, and optionally any path in that volume that you want to access directly. Get the volume information for [AWS](https://docs.databricks.com/files/volumes.html), [Azure](https://learn.microsoft.com/azure/databricks/files/volumes), or [GCP](https://docs.gcp.databricks.com/files/volumes.html).
- Make sure that the target user or service principal has access to the target volume. To learn more, see the documentation for 
  [AWS](https://docs.databricks.com/volumes/utility-commands.html#change-permissions-on-a-volume), 
  [Azure](https://learn.microsoft.com/azure/databricks/volumes/utility-commands#change-permissions-on-a-volume), 
  or [GCP](https://docs.gcp.databricks.com/volumes/utility-commands.html#change-permissions-on-a-volume).