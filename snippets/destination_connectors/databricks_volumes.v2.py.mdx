```python Python Ingest v2
import os

from unstructured_ingest.v2.pipeline.pipeline import Pipeline
from unstructured_ingest.v2.interfaces import ProcessorConfig

from unstructured_ingest.v2.processes.connectors.databricks_volumes import (
    DatabricksVolumesConnectionConfig,
    DatabricksVolumesAccessConfig,
    DatabricksVolumesUploaderConfig
)
from unstructured_ingest.v2.processes.connectors.local import (
    LocalIndexerConfig,
    LocalDownloaderConfig,
    LocalConnectionConfig
)
from unstructured_ingest.v2.processes.partitioner import PartitionerConfig
from unstructured_ingest.v2.processes.chunker import ChunkerConfig
from unstructured_ingest.v2.processes.embedder import EmbedderConfig

if __name__ == "__main__":
    Pipeline.from_configs(
        context=ProcessorConfig(),
        indexer_config=LocalIndexerConfig(input_path="local-ingest-source"),
        downloader_config=LocalDownloaderConfig(),
        source_connection_config=LocalConnectionConfig(),
        partitioner_config=PartitionerConfig(
            partition_by_api=True,
            api_key=os.getenv("UNSTRUCTURED_API_KEY"),
            partition_endpoint=os.getenv("UNSTRUCTURED_API_URL"),
            additional_partition_args={
                "split_pdf_page": True,
                "split_pdf_allow_failed": True,
                "split_pdf_concurrency_level": 15
            }
        ),
        chunker_config=ChunkerConfig(chunking_strategy="by_title"),
        embedder_config=EmbedderConfig(embedding_provider="langchain-huggingface"),
        destination_connection_config=DatabricksVolumesConnectionConfig(
            access_config=DatabricksVolumesAccessConfig(
                username=os.getenv("DATABRICKS_USERNAME"),
                password=os.getenv("DATABRICKS_PASSWORD")
            ),
            host=os.getenv("DATABRICKS_HOST")
        ),
        uploader_config=DatabricksVolumesUploaderConfig(
            catalog=os.getenv("DATABRICKS_CATALOG"),
            volume=os.getenv("DATABRICKS_VOLUME")
        )
    ).run()
```