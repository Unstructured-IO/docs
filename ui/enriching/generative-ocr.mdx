---
title: Generative OCR optimization
---

After partitioning, you can have a vision language model (VLM) optimize the fidelity of text blocks that Unstructured 
initially processed during its partitioning phase. 

Here are a few examples of Unstructured's output of text blocks that were initially processed, and the more accurate 
version of these text blocks that were optimized by using Claude Sonnet 4. Irrelevant lines of output have been omitted here for brevity. 

Example 1: Vertical watermarked text

![Vertical watermarked text example](/img/ui/enriching/generative-ocr-watermark.png)

Before (vertical watermarked text, represented incorrectly):

```json
{
    "...": "...",
    "text": "3 2 0 2 t c O 9 2 ] V C . s c [ 2 v 9 0 8 6 1 . 0 1 3 2 : v i X r",
    "...": "..."
}
```

After (vertical watermarked text, now represented correctly from the original content):

```json
{
    "...": "...",
    "text": "arXiv:2310.16809v2 [cs.CV] 29 Oct 2023",
    "...": "..."
}
```

Example 2: Hyperlink

![Hyperlinked text example](/img/ui/enriching/generative-ocr-hyperlink.png)

Before (hyperlink, represented incorrectly):

```json
{
    "...": "...",
    "text": "con/Yuliang-Liu/MultinodalOCR|",
    "...": "..."
}
```

After (hyperlink, now represented correctly from the original content):

```json
{
    "...": "...",
    "text": "https://github.com/Yuliang-Liu/MultimodalOCR",
    "...": "..."
}
```

Example 3: Chinese characters

![Chinese characters example](/img/ui/enriching/generative-ocr-image.png)

Before (Chinese characters, represented incorrectly):

```json
{
    "...": "...",
    "text": "GT SHE GPT4-V: EHES",
    "...": "..."
}
```

After (Chinese characters, now represented correctly from the original content, expressed as Unicode):

```json
{
    "...": "...",
    "text": "GT : \u91d1\u724c\u70e7\u814a GPT4-V: \u6587\u9759\u5019\u9e1f",
    "...": "..."
}
```

## Improve text fidelity with generative OCR

import EnrichmentOCRHiResOnly from '/snippets/general-shared-text/enrichment-ocr-high-res-only.mdx';

To produce generative OCR optimizations, add a **Generative OCR** node to your workflow by clicking **+** in the workflow editor, and then click **Enrich > Generative OCR**. 
Be sure also to select one of the available provider (and model) combinations that are shown.

<Warning>
    Generative OCR does not process any text blocks by default. You must also explicitly specify which document element 
    types containing text that you want generative OCR to process. To do this, in the workflow editor for your workflow:
    
    1. Click the **Partitioner** node.
    2. In the node's settings pane, scroll down to and then click a blank area inside of the **Extract Image Block Types** list.
    3. Select each [document element type](/ui/document-elements#element-type) that you want generative OCR to process. For this 
        walkthrough, select only **NarrativeText**.
    
    Generative OCR does not process the text of any `Image` or `Table` elements if they have already been processed by 
    [image description](#image-description-task) or [table description](#table-description-task) enrichments, respectively. Do 
    not remove the **Image** or **Table** document elements types from this **Extract Image Block Types** list, or else 
    the image description and table description enrichments in your workflow might produce unexpected results or might not work at all.
</Warning>

<Note>
    You can change a workflow's generative OCR settings only through [Custom](/ui/workflows#create-a-custom-workflow) workflow settings.

    For workflows that use [chunking](/ui/chunking), the **Chunker** node should be placed after all enrichment nodes. Placing the 
    **Chunker** node before an image descriptions enrichment node could cause incomplete or no image descriptions to be generated.
</Note>

<EnrichmentOCRHiResOnly />
