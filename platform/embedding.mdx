---
title: Embedding
---

After partitioning, chunking, and summarizing, the _embedding_ step creates arrays of numbers 
known as _vectors_, representing the text that is extracted by Unstructured. 
These vectors are stored or _embedded_ next to the text itself. These vector embeddings are generated by an 
[embedding model](https://python.langchain.com/v0.2/docs/concepts/#embedding-models) that is provided by 
an _embedding provider_.

You typically save these embeddings in a _vector store_. 
When a user queries a retrieval augmented generation (RAG) application, the application can use a vector database to perform 
a [similarity search](https://www.pinecone.io/learn/what-is-similarity-search/) in that vector store 
and then return the items whose embeddings are the closest to that user's query.

Here is an example of a document element generated by Unstructured, along with its vector embeddings generated by 
the embedding model [sentence-transformers/all-MiniLM-L6-v2](https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2) 
on Hugging Face:

```json
{
    "type": "Title",
    "element_id": "fdbf5369-4485-453b-9701-1bb42c83b00b",
    "text": "THE CONSTITUTION of the United States",
    "metadata": {
        "filetype": "application/pdf",
        "languages": [
            "eng"
        ],
        "page_number": 1,
        "filename": "constitution.pdf",
        "data_source": {
            "record_locator": {
                "path": "/input/constitution.pdf"
            },
            "date_created": "1723069423.0536132",
            "date_modified": "1723069423.055078",
            "date_processed": "1725666244.571788",
            "permissions_data": [
                { 
                    "mode": 33188
                }
            ]
        }
    },
    "embeddings": [
        -0.06138836592435837,
        0.08634615689516068,
        -0.019471267238259315,
        "<full-results-omitted-for-brevity>",
        0.0895417109131813,
        0.05604064092040062,
        0.01376157347112894
    ]
}
```

[Learn more](https://unstructured.io/blog/understanding-embedding-models-make-an-informed-choice-for-your-rag).

## Generate embeddings

To generate embeddings, choose one of the following embedding providers and models in the **Providers** section of an **Embedder** node in a workflow:

<Note>You can change a workflow's preconfigured provider only through [Custom](/platform/workflows#create-a-custom-workflow) workflow settings.</Note>

- **Azure OpenAI**: Use [Azure OpenAI](https://azure.microsoft.com/products/ai-services/openai-service) to generate embeddings. Also, choose the model to use:

  - **text-embedding-3-small**, with 1536 dimensions.
  - **text-embedding-3-large**, with 3072 dimensions.
  - **Ada 002 (Text)** (`text-embedding-ada-002`), with 1536 dimensions.

  [Learn more](https://learn.microsoft.com/azure/ai-services/openai/concepts/models#embeddings).

- **TogetherAI**: Use [TogetherAI](https://www.together.ai/) to generate embeddings. Also, choose the model to use:

  - **M2-BERT-80M-2K-Retrieval**, with 768 dimensions.
  - **M2-BERT-80M-8K-Retrieval**, with 768 dimensions.
  - **M2-BERT-80M-32K-Retrieval**, with 768 dimensions.
  
  [Learn more](https://docs.together.ai/docs/serverless-models#embedding-models).