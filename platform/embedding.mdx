---
title: Embedding
---

After partitioning, chunking, and summarizing, the _embedding_ step creates arrays of numbers 
known as _vectors_, representing the text that is extracted by Unstructured. 
These vectors are stored or _embedded_ next to the text itself. These vector embeddings are generated by an 
[embedding model](https://python.langchain.com/v0.2/docs/concepts/#embedding-models) that is provided by 
an _embedding provider_.

You typically save these embeddings in a _vector store_. 
When a user queries a retrieval augmented generation (RAG) application, the application can use a vector database to perform 
a [similarity search](https://www.pinecone.io/learn/what-is-similarity-search/) in that vector store 
and then return the items whose embeddings are the closest to that user's query.

Here is an example of a document element generated by Unstructured, along with its vector embeddings generated by 
the embedding model [sentence-transformers/all-MiniLM-L6-v2](https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2) 
on Hugging Face:

```json
{
    "type": "Title",
    "element_id": "fdbf5369-4485-453b-9701-1bb42c83b00b",
    "text": "THE CONSTITUTION of the United States",
    "metadata": {
        "filetype": "application/pdf",
        "languages": [
            "eng"
        ],
        "page_number": 1,
        "filename": "constitution.pdf",
        "data_source": {
            "record_locator": {
                "path": "/input/constitution.pdf"
            },
            "date_created": "1723069423.0536132",
            "date_modified": "1723069423.055078",
            "date_processed": "1725666244.571788",
            "permissions_data": [
                { 
                    "mode": 33188
                }
            ]
        }
    },
    "embeddings": [
        -0.06138836592435837,
        0.08634615689516068,
        -0.019471267238259315,
        "<full-results-omitted-for-brevity>",
        0.0895417109131813,
        0.05604064092040062,
        0.01376157347112894
    ]
}
```

[Learn more](https://unstructured.io/blog/understanding-embedding-models-make-an-informed-choice-for-your-rag).

## Generate embeddings

To generate embeddings, choose one of the following embedding providers in the **Vendor** drop-down list in the **Embed** section of a workflow:

<Note>You can change a workflow's predefined provider only through [Custom](/platform/workflows#custom-workflow-settings) workflow settings.</Note>

- **OpenAI**: Use [OpenAI](https://openai.com) to generate embeddings. Also choose the embedding model to use, from one of the following:

  - **text-embedding-3-small** (1536 dimensions): [Learn more](https://platform.openai.com/docs/guides/embeddings).
  - **text-embedding-3-large** (3072 dimensions): [Learn more](https://platform.openai.com/docs/guides/embeddings).
  - **Ada 002 (Text)** (1536 dimensions): [Learn more](https://platform.openai.com/docs/guides/embeddings).

- **Anthropic**: Use [Anthropic](https://www.anthropic.com) to generate embeddings. Also choose the embedding model to use, from one of the following:

  - **voyage-2** (1024 dimensions): [Learn more](https://docs.anthropic.com/en/docs/build-with-claude/embeddings#available-voyage-models).
  - **voyage-large-2** (1536 dimensions): [Learn more](https://docs.anthropic.com/en/docs/build-with-claude/embeddings#available-voyage-models).
  - **voyage-code-2** (1536 dimensions): [Learn more](https://docs.anthropic.com/en/docs/build-with-claude/embeddings#available-voyage-models).
  - **voyage-lite-02-instruct** (1024 dimensions): [Learn more](https://docs.anthropic.com/en/docs/build-with-claude/embeddings#available-voyage-models).

- **Hugging Face**: Use [Hugging Face](https://huggingface.co) to generate embeddings. Also choose the embedding model to use, from one of the following:

  - **nvidia/NV-Embed-v1** (4096 dimensions): [Learn more](https://huggingface.co/nvidia/NV-Embed-v1).
  - **voyage-large-2-instruct** (1024 dimensions): [Learn more](https://huggingface.co/voyageai/voyage-large-2-instruct).
  - **stella_en_400M_v5** (1024 dimensions): [Learn more](https://huggingface.co/dunzhang/stella_en_400M_v5).
  - **stella_en_1.5B_v5** (1024 dimensions): [Learn more](https://huggingface.co/dunzhang/stella_en_1.5B_v5).
  - **Alibaba-NLP/gte-Qwen2-7B-instruct** (3584 dimensions): [Learn more](https://huggingface.co/Alibaba-NLP/gte-Qwen2-7B-instruct).

- **OctoAI**: Use [OctoAI](https://octo.ai) to generate embeddings. Also choose the embedding model to use, from one of the following:

  - **GTE Large** (1024 dimensions): [Learn more](https://octo.ai/blog/introducing-octoais-embedding-api-to-power-your-rag-needs/).

- **Vertex AI**: Use [Vertex AI](https://cloud.google.com/vertex-ai) to generate embeddings. Also choose the embedding model to use, from one of the following:

  - **textembedding-gecko@003** (768 dimensions): [Learn more](https://cloud.google.com/vertex-ai/generative-ai/docs/learn/model-versions#embeddings_stable_model_versions).
  - **text-embedding-004** (768 dimensions): [Learn more](https://cloud.google.com/vertex-ai/generative-ai/docs/learn/model-versions#embeddings_stable_model_versions).
