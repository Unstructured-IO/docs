---
title: Workflows
---

## Workflows dashboard

![workflow completed](/img/platform/03b-Workflow-completed.png)

To view the workflows dashboard, on the sidebar, click **Workflows**.

A workflow in the Unstructured Platform is a defined sequence of processes that automate the data handling from source to destination. It allows users to configure how and when data should be ingested, processed, and stored.

Workflows are crucial for establishing a systematic approach to managing data flows within the platform, ensuring consistency, efficiency, and adherence to specific data processing requirements.

<Note>The **Show Ad Hoc Jobs** toggle shows or hides one-time jobs that do not repeat on a schedule.</Note>

## Create a workflow

![workflow overview](/img/platform/03a-Workflow-overview.png)

<Warning>
    You must first have an existing source connector and destination connector to add to the workflow.

    If you do not have an existing connector for either your target source (input) or destination (output) location, stop. [Create the source connector](/platform/platform-source-connectors/overview), [create the destination connector](/platform/platform-destination-connectors/overview), and then return here.

    To see your existing connectors, on the sidebar, click **Sources** or **Destinations**.
</Warning>

To create a workflow:

1. On the sidebar, click **Workflows**.
2. Click **New Workflow**.
3. Specify the workflow's settings, as described later in this section.
4. Click **Submit**.

The key components of a workflow include:

*   **Name**: A unique identifier for the workflow for easy recognition and management.
    
*   **Schedule Type**: How frequently the workflow runs. While scheduling is available for regular automated execution daily or weekly, workflows can also be triggered on a one-off basis as needed: see [Run a Job](/platform/jobs-scheduling#run-a-job).
    
*   **Sources** and **Destination**: The data's origin or input location (**Sources**) and endpoint or output location (**Destination**) for the workflow. You can configure multiple source connectors to aggregate data from various origins. You can also configure multiple destination connectors to replicate the processed data in various locations. To learn more, see [Sources](/platform/platform-source-connectors/overview) and [Destinations](/platform/platform-destination-connectors/overview).
    
*   **Strategy**: The data processing strategy. For strategy options, see "Strategy" later in this section.

*   **Options**: Workflow behaviors such as excluding specific elements, adjusting connector settings (including page breaks or retaining XML tags), and whether to reprocess all documents. To learn more, see "Options" later in this section.

*   **Chunking Options** and **Embedding Options**: Fine-tuning settings about how the data is segmented (**Chunker Type**) and the type of data encoding (**Encoder Type**) as needed. To learn more, see "Chunking Options" and "Encoding Options" later in this section.
    
To adjust a workflow's data processing behavior, set one or more of the following options:

*   **Strategy**: One of the following data processing strategies:
    
    *   **Auto** (default strategy): Chooses the partitioning strategy based on document characteristics and the function `kwargs`.
        
    *   **Fast**: Leverages traditional NLP extraction techniques to pull all text elements quickly. This strategy is not good for image-based file types.
        
    *   **Hi Res**: Uses the document layout to gain additional information about document elements. We recommend using this strategy if your use case is highly sensitive to correct classifications for document elements.
        
    *   **OCR Only**: Leverages Optical Character Recognition to extract text from the image-based files.
        
*   **Options**: Additional workflow behaviors include:
    
    *   **Elements to Exclude**: Select the [element types](/open-source/concepts/document-elements#element-type) you want to exclude from document processing. This option is useful if you want to include or exclude elements, such as `Table` or `Image` elements.
        
    *   **ConnectorSettings**: Select one or more of the following boxes to enable these behaviors:
        
        *   **Include Page Breaks**: The output includes page breaks if the file type supports it. [Learn more](/api-reference/api-services/api-parameters#include-page-breaks).
            
        *   **Infer Table Structure**: Extract tables from PDFs or images.
            
        *   **Keep XML Tags**: The output retains the XML tags. This only applies to "partition\_xml". [Learn more](/api-reference/api-services/api-parameters#xml-keep-tags).
            
        *   **Reprocess all documents**: The workflow processes any previously processed documents.

        *   **Retry failed documents (on next run)**: The next time this workflow runs, the workflow attempts to reprocess any failed documents from the previous run.
            
*   **Chunking Options**: If **Chunker Type** is set to an option other than **Off**, uses one of the following chunking strategies:
    
    *   **Chunk by Title**: When a `Title` element appears, it marks the start of a new section. The system will finish the current chunk and begin a new one, even if the current chunk has space to include the `Title` element. [Learn more](/open-source/core-functionality/chunking#by-title-chunking-strategy).
        
    *   **Basic**: Combines sequential elements to optimize the size of each chunk while adhering to the predefined "max\_characters" (hard maximum) and "new\_after\_n\_chars" (soft maximum) settings. [Learn more](/open-source/core-functionality/chunking#basic-chunking-strategy).
        
*   **Embedding Options**: Models for vectorizing and embedding the processed data. If **Encoder Type** is set to an option other than **Off**, uses one of following models:
    
    *   **OpenAI**: Enter your OpenAI **API Key** and then select the model name from the dropdown menu. [Get an OpenAI API key](https://help.openai.com/en/articles/4936850-where-do-i-find-my-openai-api-key). [Learn more](/open-source/core-functionality/embedding#openaiembeddingencoder).
        
    *   **Bedrock**: Enter your **AWS Access Key**, **AWS Secret Key**, and **AWS Region** to connect to AWS Bedrock embedding models. [Get an AWS access key and secret key](https://docs.aws.amazon.com/IAM/latest/UserGuide/id_credentials_access-keys.html). [Learn more](/open-source/core-functionality/embedding#bedrockembeddingencoder).
        
## Run a workflow

To run a workflow, [run a job](/platform/jobs-scheduling#run-a-job) for that workflow.

## Manage a workflow

![workflow actions](/img/platform/03c-Workflows-Actions.png)

For each of the workflows on the **Workflows** list page, the following actions are available in the **Actions** dropdown menu next to the respective workflow name:

*   **Edit**: Changes the existing configuration of your workflow. This can include changing the source, destination, scheduling, and chunking strategies, among other settings.
    
*   **Delete**: Removes the workflow from the platform. Use this action cautiously, as it will permanently delete the workflow and its configurations.
    
*   **Run**: Manually runs the workflow outside of its scheduled runs. This is particularly useful for testing or ad-hoc data processing needs.

## Monitor a workflow's status

![workflow status](/img/platform/03d-Workflows-Status.png)

The status of the workflows is a quick visual indicator of their current state on the **Workflows** list page. The status of your workflows can be one of the following three states:

*   **Active**: The workflow is enabled and will run as scheduled. It is ready to process data according to its configuration.
    
*   **Pause**: If you need to temporarily halt the workflow without altering its configuration, you can pause it. This is useful when the source data is undergoing maintenance, or you're implementing changes that may affect the workflow's operation.
    
*   **Archive**: Workflows that are no longer in use but need to be kept for record keeping or compliance purposes can be archived. This status removes the workflow from active duty without deleting its setup.
    

