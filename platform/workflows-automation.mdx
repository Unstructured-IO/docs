---
title: Workflows
---

## Workflows dashboard

![Workflows in the sidebar](/img/platform/Workflows-Sidebar.png)

To view the workflows dashboard, on the sidebar, click **Workflows**.

A workflow in the Unstructured Platform is a defined sequence of processes that automate the data handling from source to destination. It allows users to configure how and when data should be ingested, processed, and stored.

Workflows are crucial for establishing a systematic approach to managing data flows within the platform, ensuring consistency, efficiency, and adherence to specific data processing requirements.

## Create a workflow

![Create workflow](/img/platform/Create-Workflow.png)

<Warning>
    You must first have an existing source connector and destination connector to add to the workflow.

    If you do not have an existing connector for either your target source (input) or destination (output) location, stop. [Create the source connector](/platform/platform-source-connectors/overview), [create the destination connector](/platform/platform-destination-connectors/overview), and then return here.

    To see your existing connectors, on the sidebar, click **Sources** or **Destinations**.
</Warning>

To create a workflow:

1. On the sidebar, click **Workflows**.
2. Click **New Workflow**.
3. Enter a unique **Name** for this workflow.
4. Specify the workflow's settings as follows, and then click **Save**.

<AccordionGroup>
    <Accordion title="Transform section">
        1. For **Strategy**, choose one of the following:

           - **High Res**: This strategy uses document layout to gain additional information about document elements. Unstructured recommends using this strategy if your use case is highly sensitive to correct classifications for document elements. [Learn more](/api-reference/api-services/partitioning).
           - **Auto**: This strategy chooses the partitioning strategy based on detected document characteristics. [Learn more](/api-reference/api-services/partitioning).
           - **Fast**: This strategy uses traditional NLP extraction techniques to quickly pull in all text elements. This strategy is not good for image-based file types. [Learn more](/api-reference/api-services/partitioning).
           - **OCR Only**: This strategy uses optical character recognition (OCR) to extract text from image-based files. [Learn more](/api-reference/api-services/partitioning).

        2. For **Image summarization**, choose one of the following:

           - **None**: No summarization of images.
           - **GPT-4o**: Use GPT-4o to summarize images. [Learn more](https://openai.com/index/hello-gpt-4o/).
           - **Claude 3.5 Sonnet**: Use Claude 3.5 Sonnet to summarize images. [Learn more](https://www.anthropic.com/news/claude-3-5-sonnet).

        3. For **Table summarization**, choose one of the following:

           - **None**: No summarization of tables.
           - **GPT-4o**: Use GPT-4o to summarize tables. [Learn more](https://openai.com/index/hello-gpt-4o/).
           - **Claude 3.5 Sonnet**: Use Claude 3.5 Sonnet to summarize tables. [Learn more](https://www.anthropic.com/news/claude-3-5-sonnet).

        4. For **ConnectorSettings**, check one or more of the following boxes:

           - **Include Page Breaks**: Include page breaks in the output, if the file type supports it.
           - **Infer Table Structure**: If you also set **Strategy** to **High Res**, any table elements extracted from a PDF will include an additional metadata field, `text_as_html`, that contains a transformation of the data into an HTML `<table>`.
           - **Reprocess all documents**: This workflow will processes any previously processed documents.

        5. For **Elements to Exclude**, select one or more standard Unstructured element types to not include in the output. [Learn more](/api-reference/api-services/document-elements).
    </Accordion>
    <Accordion title="Chunk section">
        For **Chunker Type**, select one of the following:

        - **None**: Do not chunk elements.
        - **Basic**: Combine sequential elements to maximally fill each chunk. [Learn more](/api-reference/api-services/chunking). Also specify the following:

          - **Include Original Elements**: Check this box to output the elements that were used to form a chunk, to appear in the `metadata` field's `orig_elements` field for that chunk.
          - **Max Characters** (_required_): Cut off new sections after reaching a length of this many characters.
          - **New After N Characters** (_required_): Cut off new sections after reaching a length of this many characters. This is an approximate limit.
          - **Overlap** (_required_): Apply a prefix of this many trailing characters from the prior text-split chunk to second and later chunks formed from oversized elements by text-splitting.
          - **Overlap All**: Check this box to apply overlap to "normal" chunks formed by combining whole elements. Use with caution as this can introduce noise into otherwise clean semantic units.

        - **Chunk By Title**: Preserve section boundaries and optionally page boundaries as well. A single chunk will never contain text that occurred in two different sections. When a new section starts, the existing chunk is closed and a new one is started, even if the next element would fit in the prior chunk. [Learn more](/api-reference/api-services/chunking). Also specify the following:
        
          - **Combine Text Under N Characters** (_required_): Combine elements until a section reaches a length of this many characters.
          - **Include Original Elements**: Check this box to output the elements that were used to form a chunk, to appear in the `metadata` field's `orig_elements` field for that chunk.
          - **Max Characters** (_required_): Cut off new sections after reaching a length of this many characters. This is a strict limit.
          - **Multipage Sections**: Check this box to allow sections to span multiple pages.
          - **New After N Characters** (_required_): Cut off new sections after reaching a length of this many characters. This is an approximate limit.
          - **Overlap** (_required_): Apply a prefix of this many trailing characters from the prior text-split chunk to second and later chunks formed from oversized elements by text-splitting.
          - **Overlap All**: Check this box to apply overlap to "normal" chunks formed by combining whole elements. Use with caution as this can introduce noise into otherwise clean semantic units.

        - **Chunk By Page**: Preserve page boundaries. When a new page is detected, the existing chunk is closed and a new one is started, even if the next element would fit in the prior chunk. [Learn more](/api-reference/api-services/chunking). Also specify the following:
        
          - **Include Original Elements**: Check this box to output the elements that were used to form a chunk, to appear in the `metadata` field's `orig_elements` field for that chunk.
          - **Max Characters** (_required_): Cut off new sections after reaching a length of this many characters. This is a strict limit.
          - **New After N Characters** (_required_): Cut off new sections after reaching a length of this many characters. This is an approximate limit.
          - **Overlap** (_required_): Apply a prefix of this many trailing characters from the prior text-split chunk to second and later chunks formed from oversized elements by text-splitting.
          - **Overlap All**: Check this box to apply overlap to "normal" chunks formed by combining whole elements. Use with caution as this can introduce noise into otherwise clean semantic units.
        
        - **Chunk By Similarity**: Use the [sentence-transformers/multi-qa-mpnet-base-dot-v1](https://huggingface.co/sentence-transformers/multi-qa-mpnet-base-dot-v1) embedding model to identify topically similar sequential elements and combine them into chunks. [Learn more](/api-reference/api-services/chunking). Also specify the following:

          - **Include Original Elements**: Check this box to output the elements that were used to form a chunk, to appear in the `metadata` field's `orig_elements` field for that chunk.
          - **Max Characters** (_required_): Cut off new sections after reaching a length of this many characters. This is a strict limit.
          - **Similarity Threshold** (_required_): Specify a threshold between 0 and 1, where 0 indicates completely dissimilar vectors and 1 indicates identical vectors, taking into consider the trade-offs between precision (a higher threshold) and recall (a lower threshold). [Learn more](https://towardsdatascience.com/introduction-to-embedding-clustering-and-similarity-11dd80b00061).

        [Learn more](https://unstructured.io/blog/chunking-for-rag-best-practices).
    </Accordion>
    <Accordion title="Embed section">
        For **Vendor**, select one of the following:

        - **Off**: Do not generate embeddings.
        - **OpenAI**: Use OpenAI to generate embeddings. Also choose the embedding model to use, from one of the following:

          - **text-embedding-3-small**: [Learn more](https://platform.openai.com/docs/guides/embeddings).
          - **text-embedding-3-large**: [Learn more](https://platform.openai.com/docs/guides/embeddings).
          - **Ada 002 (Text)**: [Learn more](https://platform.openai.com/docs/guides/embeddings).

        - **Anthropic**: Use Anthropic to generate embeddings. Also choose the embedding model to use, from one of the following:

          - **voyage-2**: [Learn more](https://docs.anthropic.com/en/docs/build-with-claude/embeddings#available-voyage-models).
          - **voyage-large-2**: [Learn more](https://docs.anthropic.com/en/docs/build-with-claude/embeddings#available-voyage-models).
          - **voyage-code-2**: [Learn more](https://docs.anthropic.com/en/docs/build-with-claude/embeddings#available-voyage-models).
          - **voyage-lite-02-instruct**: [Learn more](https://docs.anthropic.com/en/docs/build-with-claude/embeddings#available-voyage-models).
        
        - **Hugging Face**: Use Hugging Face to generate embeddings. Also choose the embedding model to use, from one of the following:

          - **nvidia/NV-Embed-v1**: [Learn more](https://huggingface.co/nvidia/NV-Embed-v1).
          - **voyage-large-2-instruct**: [Learn more](https://huggingface.co/voyageai/voyage-large-2-instruct).
          - **stella_en_400M_v5**: [Learn more](https://huggingface.co/dunzhang/stella_en_400M_v5).
          - **stella_en_1.5B_v5**: [Learn more](https://huggingface.co/dunzhang/stella_en_1.5B_v5).
          - **Alibaba-NLP/gte-Qwen2-7B-instruct**: [Learn more](https://huggingface.co/Alibaba-NLP/gte-Qwen2-7B-instruct).

        - **OctoAI**: Use OctoAI to generate embeddings. Also choose the embedding model to use, from one of the following:

          - **GTE Large**: [Learn more](https://octo.ai/blog/introducing-octoais-embedding-api-to-power-your-rag-needs/).

        - **Vertex AI**: Use Vertex AI to generate embeddings. Also choose the embedding model to use, from one of the following:

          - **textembedding-gecko@003**: [Learn more](https://cloud.google.com/vertex-ai/generative-ai/docs/learn/model-versions#embeddings_stable_model_versions).
          - **text-embedding-004**: [Learn more](https://cloud.google.com/vertex-ai/generative-ai/docs/learn/model-versions#embeddings_stable_model_versions).

        [Learn more](https://unstructured.io/blog/understanding-embedding-models-make-an-informed-choice-for-your-rag).
    </Accordion>
    <Accordion title="Connect section">
        1. For **Sources** (_required_), choose one or more of the existing source connections from the **Sources** section in the sidebar. [Learn more](/platform/platform-source-connectors/overview).
        2. For **Destinations** (_required_), choose one or more of the existing destination connections from the **Destinations** section in the sidebar. [Learn more](/platform/platform-destination-connectors/overview). 
    
        <Note>You can select multiple source and destination locations. Files will be ingested from all of the selected source locations, and the processed data will be delivered to all of the selected destination locations.</Note>
    </Accordion>
    <Accordion title="Schedule section">
        For **Schedule Type**, choose one of the following:

        - **Off**: This workflow will not run automatically. To run this workflow, [create and run a job manually](/platform/jobs-scheduling).
        - **Monthly**: This workflow will automatically run once each month. Choose the day of the month and the time on that day to run this workflow.
        - **Daily**: This workflow will automatically run once each day for one or more days of each week. Choose the days of the week and the time on each of those days to run this workflow.
        - **Hourly**: This workflow will automatically run once each hour. Choose the minute of the hour to run this workflow.
        - **Frequently**: This workflow will automatically run once after each specified number of minutes. Choose the time period in minutes to wait until running this workflow again.
    </Accordion>
</AccordionGroup>

## Edit, delete, or run a workflow

![Manage a workflow](/img/platform/Workflow-Actions.png)

For each of the workflows on the **Workflows** list page, the following actions are available by clicking the ellipses (the three dots) next to the respective workflow name:

*   **Edit**: Changes the existing configuration of your workflow. This can include changing the source, destination, scheduling, and chunking strategies, among other settings.
    
*   **Delete**: Removes the workflow from the platform. Use this action cautiously, as it will permanently delete the workflow and its configurations.
    
*   **Run**: Manually runs the workflow outside of its scheduled runs. This is particularly useful for testing or ad-hoc data processing needs.

